results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "why are you so "
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "im tired"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "ashley is"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "ashley is a"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "greatest in the"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "the world is a"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "came was white i"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "mens room and they"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "white electric the argument "
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "white dogwoods english roses"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "The guy in front of me just bought a pound of bacon, a bouquet, and a case of"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
returnResults(clean_entry)
sent <- "You're the reason why I smile everyday. Can you follow me please? It would mean the"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults(clean_entry)
sent <- "Hey sunshine, can you follow me and make me the"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
returnResults(clean_entry)
library(tm)
library(openNLP)
library(RWeka)
library(dplyr)
library(stringr)
library(slam)
library(data.table)
library(stringr)
setwd("/Users/brianhudnall/Programming/R/NLP_Capstone/final/en_US/")
library(tm)
library(openNLP)
library(RWeka)
library(dplyr)
library(stringr)
library(slam)
library(data.table)
library(stringr)
# Load profanity list
profanity <- read.table("profanity.txt", header = FALSE, sep = "\n")
# this function will pull the data from the data files
# and create a sample that is large enough to be accurate
# but not to big to be manageable. it relies on the
# rbinom function
createSample <- function(file_name, size, prob = 0.5) {
lines_file <- readLines(file_name, skipNul = TRUE)
lines_file <- lines_file[rbinom(
length(lines_file) * size,
length(lines_file),
prob
)]
close(file_name)
return(lines_file)
}
# this function creates the corpus and lowers the font,
# strips whitespace, removes punctuation, numbers, profanity,
# and then converts it to a plain text document. It relies
# heavily on the tm library
create_corpus <- function(x) {
corpus <- VCorpus(VectorSource(x))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, profanity[1,])
corpus <- tm_map(corpus, PlainTextDocument)
corpus
}
# these functions create the bigram, trigram, quadgram and pentagram
bigram_token <- function(x) NGramTokenizer(x, Weka_control(min=2, max=2))
trigram_token <- function(x) NGramTokenizer(corpus, Weka_control(min=3, max=3))
quadgram_token <- function(x) NGramTokenizer(corpus, Weka_control(min=4, max=4))
pentagram_token <- function(x) NGramTokenizer(corpus, Weka_control(min=5, max=5))
# this function finds the length of the phrase being passed
# and then based on length will filter the top n-gram to predict
# the next word. it relies on the getResults function below.
returnResults <- function(sent) {
results_df <- data.frame(pred = character(), count = integer())
for (word in min(length(sent), 4):1) {
final_sent <- paste(tail(sent, word), collapse = " ")
if (word == 4) {
results_df <- bind_rows(results_df, getResults(final_sent, pentagram_df))
} else if (word == 3) {
results_df <- bind_rows(results_df, getResults(final_sent, quadgram_df))
} else if (word == 2) {
results_df <- bind_rows(results_df, getResults(final_sent, trigram_df))
} else {
results_df <- bind_rows(results_df, getResults(final_sent, bigram_df))
}
}
as.character(results_df[1,1])
}
# used by the returnResults function to filter
# the dataframes and pull in the top 2 results
# per N-gram
getResults <- function(final_sent, df) {
results <- df %>%
filter(prev == final_sent) %>%
top_n(2, count) %>%
select(pred, count)
}
# for each phrase pull on the words before the last word in the
# sentence and also the last word of the sentence
parsePhrase <- function(df) {
df <- df %>% mutate(prev = str_trim(str_match(phrase, ".*[^a-z]+")),
pred = str_trim(str_match(phrase, "[ ]+?[a-z]+$")))
}
library(tm)
library(openNLP)
library(RWeka)
library(dplyr)
library(stringr)
library(slam)
library(data.table)
library(stringr)
source('functions.r')
# Set the wd
setwd("/Users/brianhudnall/Programming/R/NLP_Capstone/final/en_US/")
# pull in the data
twitter <- createSample(file("en_US.twitter.txt", "r"), .003)
blogs <- createSample(file("en_US.blogs.txt", "r"), .006)
news <- createSample(file("en_US.news.txt", "r"), .006)
# combine sources into a connected list
lines_collapsed <- paste(twitter, blogs, news, collapse = " ")
# create the corpus
corpus <- create_corpus(lines_collapsed)
# create the N-grams
bigram <- bigram_token(corpus)
trigram <- trigram_token(corpus)
quadgram <- quadgram_token(corpus)
pentagram <- pentagram_token(corpus)
# create the term document matrix
bi_tdm <- TermDocumentMatrix(corpus, control = list(tokenize = bigram_token))
tri_tdm <- TermDocumentMatrix(corpus, control = list(tokenize = trigram_token))
quad_tdm <- TermDocumentMatrix(corpus, control = list(tokenize = quadgram_token))
pent_tdm <- TermDocumentMatrix(corpus, control = list(tokenize = pentagram_token))
# create dataframes of the N-grams
bigram_df <- as.data.frame(table(bigram))
trigram_df <- as.data.frame(table(trigram))
quadgram_df <- as.data.frame(table(quadgram))
pentagram_df <- as.data.frame(table(pentagram))
# order the n-gram dataframes
bigram_df <- bigram_df[order(bigram_df$Freq, decreasing = TRUE),]
trigram_df <- trigram_df[order(trigram_df$Freq, decreasing = TRUE),]
quadgram_df <- quadgram_df[order(quadgram_df$Freq, decreasing = TRUE),]
pentagram_df <- pentagram_df[order(pentagram_df$Freq, decreasing = TRUE),]
# assign the column names to the dataframes
colnames(bigram_df) <- c("phrase", "count")
colnames(trigram_df) <- c("phrase", "count")
colnames(quadgram_df) <- c("phrase", "count")
colnames(pentagram_df) <- c("phrase", "count")
# parse the previous and current words
bigram_df <<- parsePhrase(bigram_df)
trigram_df <<- parsePhrase(trigram_df)
quadgram_df <<- parsePhrase(quadgram_df)
pentagram_df <<- parsePhrase(pentagram_df)
View(pentagram_df)
sent <- "by the end of"
clean_entry <- tolower(sent) %>%
removeNumbers %>%
removePunctuation() %>%
stripWhitespace() %>%
str_trim %>%
strsplit(split = " ") %>%
unlist
print(returnResults(clean_entry))
rm(sent)
setwd("/Users/brianhudnall/Programming/R/NLP_Capstone/final/")
